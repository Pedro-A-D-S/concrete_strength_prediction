{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous notebook we've identified, analyzed and solved the inconsistences in our dataset. In some cases, for machine learning models, it is necessary to create new features to model the problem. This notebook aims to do the necessary feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "%matplotlib inline\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, BaggingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import metrics\n",
    "from scipy import stats\n",
    "from scipy.stats import zscore\n",
    "from sklearn.metrics import mean_absolute_error, median_absolute_error, r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost.sklearn import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('Concrete_Data_Cleaned.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cement</th>\n",
       "      <th>slag</th>\n",
       "      <th>ash</th>\n",
       "      <th>water</th>\n",
       "      <th>superplastic</th>\n",
       "      <th>coarseagg</th>\n",
       "      <th>fineagg</th>\n",
       "      <th>age</th>\n",
       "      <th>strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>272.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>272.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>28</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>28</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>28</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cement   slag  ash  water  superplastic  coarseagg  fineagg  age  strength\n",
       "0   272.9    0.0  0.0  162.0           2.5     1040.0    676.0   28     79.99\n",
       "1   272.9    0.0  0.0  162.0           2.5     1055.0    676.0   28     61.89\n",
       "2   332.5  142.5  0.0  185.0           0.0      932.0    594.0   28     40.27\n",
       "3   332.5  142.5  0.0  185.0           0.0      932.0    594.0   28     41.05\n",
       "4   198.6  132.4  0.0  192.0           0.0      978.4    825.5   28     44.30"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The strength is the target variable, let's divide the dataset in dependent and independent variables and scale the data avoid data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cement', 'slag', 'ash', 'water', 'superplastic', 'coarseagg',\n",
       "       'fineagg', 'age', 'strength'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spitting data into dependent and independent variables\n",
    "\n",
    "X = df[['cement', 'slag', 'ash', 'water', 'superplastic', 'coarseagg',\n",
    "       'fineagg', 'age']]\n",
    "y = df[['strength']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to scale our data, let us use the z score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xscaled = X.apply(zscore)\n",
    "X_scaled_df = pd.DataFrame(Xscaled, columns = df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled_df = X_scaled_df.drop(columns = 'strength')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cement</th>\n",
       "      <th>slag</th>\n",
       "      <th>ash</th>\n",
       "      <th>water</th>\n",
       "      <th>superplastic</th>\n",
       "      <th>coarseagg</th>\n",
       "      <th>fineagg</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.147951</td>\n",
       "      <td>-0.830600</td>\n",
       "      <td>-0.822730</td>\n",
       "      <td>-1.004275</td>\n",
       "      <td>-0.618977</td>\n",
       "      <td>1.262346</td>\n",
       "      <td>-1.282281</td>\n",
       "      <td>0.300203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.147951</td>\n",
       "      <td>-0.830600</td>\n",
       "      <td>-0.822730</td>\n",
       "      <td>-1.004275</td>\n",
       "      <td>-0.618977</td>\n",
       "      <td>1.496911</td>\n",
       "      <td>-1.282281</td>\n",
       "      <td>0.300203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.892690</td>\n",
       "      <td>1.130849</td>\n",
       "      <td>-0.822730</td>\n",
       "      <td>0.396167</td>\n",
       "      <td>-1.156464</td>\n",
       "      <td>-0.426523</td>\n",
       "      <td>-2.543096</td>\n",
       "      <td>0.300203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.892690</td>\n",
       "      <td>1.130849</td>\n",
       "      <td>-0.822730</td>\n",
       "      <td>0.396167</td>\n",
       "      <td>-1.156464</td>\n",
       "      <td>-0.426523</td>\n",
       "      <td>-2.543096</td>\n",
       "      <td>0.300203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.780475</td>\n",
       "      <td>0.991827</td>\n",
       "      <td>-0.822730</td>\n",
       "      <td>0.822389</td>\n",
       "      <td>-1.156464</td>\n",
       "      <td>0.299065</td>\n",
       "      <td>1.016402</td>\n",
       "      <td>0.300203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>0.191685</td>\n",
       "      <td>0.766088</td>\n",
       "      <td>0.642499</td>\n",
       "      <td>0.067368</td>\n",
       "      <td>0.756991</td>\n",
       "      <td>-1.394495</td>\n",
       "      <td>0.136906</td>\n",
       "      <td>0.300203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>0.763985</td>\n",
       "      <td>-0.830600</td>\n",
       "      <td>1.053023</td>\n",
       "      <td>1.065944</td>\n",
       "      <td>1.079483</td>\n",
       "      <td>-2.210781</td>\n",
       "      <td>0.830354</td>\n",
       "      <td>0.300203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>-1.406506</td>\n",
       "      <td>1.088179</td>\n",
       "      <td>0.939440</td>\n",
       "      <td>0.865011</td>\n",
       "      <td>0.155005</td>\n",
       "      <td>-1.045775</td>\n",
       "      <td>0.316803</td>\n",
       "      <td>0.300203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>-1.274052</td>\n",
       "      <td>1.739242</td>\n",
       "      <td>-0.822730</td>\n",
       "      <td>-0.176187</td>\n",
       "      <td>1.272979</td>\n",
       "      <td>0.474207</td>\n",
       "      <td>0.453647</td>\n",
       "      <td>0.300203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>-0.001997</td>\n",
       "      <td>0.552738</td>\n",
       "      <td>0.447784</td>\n",
       "      <td>1.346033</td>\n",
       "      <td>0.692492</td>\n",
       "      <td>-1.482066</td>\n",
       "      <td>0.032350</td>\n",
       "      <td>0.300203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1030 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        cement      slag       ash     water  superplastic  coarseagg  \\\n",
       "0     0.147951 -0.830600 -0.822730 -1.004275     -0.618977   1.262346   \n",
       "1     0.147951 -0.830600 -0.822730 -1.004275     -0.618977   1.496911   \n",
       "2     0.892690  1.130849 -0.822730  0.396167     -1.156464  -0.426523   \n",
       "3     0.892690  1.130849 -0.822730  0.396167     -1.156464  -0.426523   \n",
       "4    -0.780475  0.991827 -0.822730  0.822389     -1.156464   0.299065   \n",
       "...        ...       ...       ...       ...           ...        ...   \n",
       "1025  0.191685  0.766088  0.642499  0.067368      0.756991  -1.394495   \n",
       "1026  0.763985 -0.830600  1.053023  1.065944      1.079483  -2.210781   \n",
       "1027 -1.406506  1.088179  0.939440  0.865011      0.155005  -1.045775   \n",
       "1028 -1.274052  1.739242 -0.822730 -0.176187      1.272979   0.474207   \n",
       "1029 -0.001997  0.552738  0.447784  1.346033      0.692492  -1.482066   \n",
       "\n",
       "       fineagg       age  \n",
       "0    -1.282281  0.300203  \n",
       "1    -1.282281  0.300203  \n",
       "2    -2.543096  0.300203  \n",
       "3    -2.543096  0.300203  \n",
       "4     1.016402  0.300203  \n",
       "...        ...       ...  \n",
       "1025  0.136906  0.300203  \n",
       "1026  0.830354  0.300203  \n",
       "1027  0.316803  0.300203  \n",
       "1028  0.453647  0.300203  \n",
       "1029  0.032350  0.300203  \n",
       "\n",
       "[1030 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Different Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting in train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xscaled, y, test_size = 0.3, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest model\n",
    "model = RandomForestRegressor()\n",
    "# fitting model\n",
    "model.fit(X_train, y_train)\n",
    "# predicted values\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9649571234165295"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model performance on training data\n",
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8401559845641612"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model performance on testing data\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_R = metrics.r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8401559845641612"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE = metrics.mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.896267164944994"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has overfitted because the train and test scores are supposed to be closer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.840156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Algorithm  accuracy\n",
       "1  Random Forest  0.840156"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the accuracy results for each model in a dataframe for final comparison\n",
    "results_1 = pd.DataFrame({'Algorithm':'Random Forest', 'accuracy': acc_R}, index = {'1'})\n",
    "results = results_1[['Algorithm', 'accuracy']]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KFold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8622271558869248"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 20\n",
    "# creating k experiments in the dataset and taking its mean accuracy\n",
    "kfold = KFold(n_splits = k, random_state = 70, shuffle = True)\n",
    "K_results = cross_val_score(model, X, y, cv = kfold)\n",
    "accuracy = np.mean(abs(K_results))\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.840156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest Regressor k_fold</td>\n",
       "      <td>0.862227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Algorithm  accuracy\n",
       "1                   Random Forest  0.840156\n",
       "2  Random Forest Regressor k_fold  0.862227"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the accuracy results for each model in a dataframe\n",
    "random_re = pd.DataFrame({'Algorithm':['Random Forest Regressor k_fold'], 'accuracy': [accuracy]}, index = {'2'})\n",
    "results = pd.concat([results, random_re])\n",
    "results = results[['Algorithm', 'accuracy']]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient boosting model\n",
    "model = GradientBoostingRegressor()\n",
    "# fitting model\n",
    "model.fit(X_train, y_train)\n",
    "# predicted values\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9129121071009074"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model performance on training data\n",
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8302527218599342"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model performance on testing data\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8302527218599342"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_G = metrics.r2_score(y_test, y_pred)\n",
    "acc_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44.49198361344398"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE = metrics.mean_squared_error(y_test, y_pred)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.840156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest Regressor k_fold</td>\n",
       "      <td>0.862227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.830253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Algorithm  accuracy\n",
       "1                   Random Forest  0.840156\n",
       "2  Random Forest Regressor k_fold  0.862227\n",
       "3               Gradient Boosting  0.830253"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the accuracy results for each model in a dataframe\n",
    "gradient_re = pd.DataFrame({'Algorithm':['Gradient Boosting'], 'accuracy': [acc_G]}, index = {'3'})\n",
    "results = pd.concat([results, gradient_re])\n",
    "results = results[['Algorithm', 'accuracy']]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KFold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8554751073973492"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 20\n",
    "# creating k experiments in the dataset and taking its mean accuracy\n",
    "kfold = KFold(n_splits = k, random_state = 70, shuffle = True)\n",
    "results_3 = cross_val_score(model, X, y, cv = kfold)\n",
    "accuracy = np.mean(abs(results_3))\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.840156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest Regressor k_fold</td>\n",
       "      <td>0.862227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.830253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boosting k_fold</td>\n",
       "      <td>0.855475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Algorithm  accuracy\n",
       "1                   Random Forest  0.840156\n",
       "2  Random Forest Regressor k_fold  0.862227\n",
       "3               Gradient Boosting  0.830253\n",
       "4        Gradient Boosting k_fold  0.855475"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the accuracy results for each model in a dataframe\n",
    "gradient_k = pd.DataFrame({'Algorithm':['Gradient Boosting k_fold'], 'accuracy': [accuracy]}, index = {'4'})\n",
    "results = pd.concat([results, gradient_k])\n",
    "results = results[['Algorithm', 'accuracy']]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ada Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ada boosting model\n",
    "model = AdaBoostRegressor()\n",
    "# fitting model\n",
    "model.fit(X_train, y_train)\n",
    "# predicted values\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7638031797203251"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model performance on training data\n",
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7077312909213798"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa_Ada = metrics.r2_score(y_test, y_pred)\n",
    "aa_Ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76.60573269586416"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE = metrics.mean_squared_error(y_test, y_pred)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.840156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest Regressor k_fold</td>\n",
       "      <td>0.862227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.830253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boosting k_fold</td>\n",
       "      <td>0.855475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ada Boosting</td>\n",
       "      <td>0.707731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Algorithm  accuracy\n",
       "1                   Random Forest  0.840156\n",
       "2  Random Forest Regressor k_fold  0.862227\n",
       "3               Gradient Boosting  0.830253\n",
       "4        Gradient Boosting k_fold  0.855475\n",
       "5                    Ada Boosting  0.707731"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the accuracy results for each model in a dataframe\n",
    "acc_Ada = pd.DataFrame({'Algorithm':['Ada Boosting'], 'accuracy': [aa_Ada]}, index = {'5'})\n",
    "results = pd.concat([results, acc_Ada])\n",
    "results = results[['Algorithm', 'accuracy']]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7238673786462161"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 20\n",
    "# creating k experiments in the dataset and taking its mean accuracy\n",
    "kfold = KFold(n_splits = k, random_state = 70, shuffle = True)\n",
    "results_4 = cross_val_score(model, X, y, cv = kfold)\n",
    "accuracy = np.mean(abs(results_4))\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.840156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest Regressor k_fold</td>\n",
       "      <td>0.862227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.830253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boosting k_fold</td>\n",
       "      <td>0.855475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ada Boosting</td>\n",
       "      <td>0.707731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ada Boosting k_fold</td>\n",
       "      <td>0.723867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Algorithm  accuracy\n",
       "1                   Random Forest  0.840156\n",
       "2  Random Forest Regressor k_fold  0.862227\n",
       "3               Gradient Boosting  0.830253\n",
       "4        Gradient Boosting k_fold  0.855475\n",
       "5                    Ada Boosting  0.707731\n",
       "6             Ada Boosting k_fold  0.723867"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the accuracy results for each model in a dataframe\n",
    "acc_AdaC = pd.DataFrame({'Algorithm':['Ada Boosting k_fold'], 'accuracy': [accuracy]}, index = {'6'})\n",
    "results = pd.concat([results, acc_AdaC])\n",
    "results = results[['Algorithm', 'accuracy']]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for different values of neighbors to determine the best number\n",
    "\n",
    "diff_k = []\n",
    "for i in range(1, 45):\n",
    "    knn = KNeighborsRegressor(n_neighbors = i)\n",
    "    knn.fit(X_train, y_train)\n",
    "    pred_i = knn.predict(X_test)\n",
    "    diff_k.append(np.mean(pred_i != y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us visualize the mean error for each value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Mean error')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (12, 6))\n",
    "plt.plot(range(1, 45), diff_k, color = 'blue', linestyle = 'dashed', marker = 'o', markerfacecolor = 'red', markersize = 10)\n",
    "plt.title('Different K - Values', fontsize = 20)\n",
    "plt.xlabel('K Values', fontsize = 15)\n",
    "plt.ylabel('Mean error', fontsize = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 3 is a better choice\n",
    "model = KNeighborsRegressor(n_neighbors = 3)\n",
    "# fitting model\n",
    "model.fit(X_train, y_train)\n",
    "# predicted values\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8926750114787164"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model performance on training data\n",
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7327995451983497"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_KNN = metrics.r2_score(y_test, y_pred)\n",
    "acc_KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70.03516278317151"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE = metrics.mean_squared_error(y_test, y_pred)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.840156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest Regressor k_fold</td>\n",
       "      <td>0.862227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.830253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boosting k_fold</td>\n",
       "      <td>0.855475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ada Boosting</td>\n",
       "      <td>0.707731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ada Boosting k_fold</td>\n",
       "      <td>0.723867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNN Regressor</td>\n",
       "      <td>0.732800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Algorithm  accuracy\n",
       "1                   Random Forest  0.840156\n",
       "2  Random Forest Regressor k_fold  0.862227\n",
       "3               Gradient Boosting  0.830253\n",
       "4        Gradient Boosting k_fold  0.855475\n",
       "5                    Ada Boosting  0.707731\n",
       "6             Ada Boosting k_fold  0.723867\n",
       "7                   KNN Regressor  0.732800"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the accuracy results for each model in a dataframe\n",
    "KNN_df = pd.DataFrame({'Algorithm':['KNN Regressor'], 'accuracy': [acc_KNN]}, index = {'7'})\n",
    "results = pd.concat([results, KNN_df])\n",
    "results = results[['Algorithm', 'accuracy']]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kfold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5648537541937363"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 20\n",
    "# creating k experiments in the dataset and taking its mean accuracy\n",
    "kfold = KFold(n_splits = k, random_state = 70, shuffle = True)\n",
    "results_5 = cross_val_score(model, X, y, cv = kfold)\n",
    "accuracy = np.mean(abs(results_5))\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.840156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest Regressor k_fold</td>\n",
       "      <td>0.862227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.830253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boosting k_fold</td>\n",
       "      <td>0.855475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ada Boosting</td>\n",
       "      <td>0.707731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ada Boosting k_fold</td>\n",
       "      <td>0.723867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNN Regressor</td>\n",
       "      <td>0.732800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNN Regressor kfold</td>\n",
       "      <td>0.564854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Algorithm  accuracy\n",
       "1                   Random Forest  0.840156\n",
       "2  Random Forest Regressor k_fold  0.862227\n",
       "3               Gradient Boosting  0.830253\n",
       "4        Gradient Boosting k_fold  0.855475\n",
       "5                    Ada Boosting  0.707731\n",
       "6             Ada Boosting k_fold  0.723867\n",
       "7                   KNN Regressor  0.732800\n",
       "8             KNN Regressor kfold  0.564854"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the accuracy results for each model in a dataframe\n",
    "KNNKfold_df = pd.DataFrame({'Algorithm':['KNN Regressor kfold'], 'accuracy': [accuracy]}, index = {'8'})\n",
    "results = pd.concat([results, KNNKfold_df])\n",
    "results = results[['Algorithm', 'accuracy']]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bagging regressor model\n",
    "model = BaggingRegressor()\n",
    "# fitting model\n",
    "model.fit(X_train, y_train)\n",
    "# predicted values\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9579376184061787"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model performance on training data\n",
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8369428852219609"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8369428852219609"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_BR = metrics.r2_score(y_test, y_pred)\n",
    "acc_BR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.73844363368096"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE = metrics.mean_squared_error(y_test, y_pred)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.840156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest Regressor k_fold</td>\n",
       "      <td>0.862227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.830253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boosting k_fold</td>\n",
       "      <td>0.855475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ada Boosting</td>\n",
       "      <td>0.707731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ada Boosting k_fold</td>\n",
       "      <td>0.723867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNN Regressor</td>\n",
       "      <td>0.732800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNN Regressor kfold</td>\n",
       "      <td>0.564854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bagging Regressor</td>\n",
       "      <td>0.836943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Algorithm  accuracy\n",
       "1                   Random Forest  0.840156\n",
       "2  Random Forest Regressor k_fold  0.862227\n",
       "3               Gradient Boosting  0.830253\n",
       "4        Gradient Boosting k_fold  0.855475\n",
       "5                    Ada Boosting  0.707731\n",
       "6             Ada Boosting k_fold  0.723867\n",
       "7                   KNN Regressor  0.732800\n",
       "8             KNN Regressor kfold  0.564854\n",
       "9               Bagging Regressor  0.836943"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the accuracy results for each model in a dataframe\n",
    "BR_df = pd.DataFrame({'Algorithm':['Bagging Regressor'], 'accuracy': [acc_BR]}, index = {'9'})\n",
    "results = pd.concat([results, BR_df])\n",
    "results = results[['Algorithm', 'accuracy']]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kfold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8529692916591252"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 20\n",
    "# creating k experiments in the dataset and taking its mean accuracy\n",
    "kfold = KFold(n_splits = k, random_state = 70, shuffle = True)\n",
    "results_6 = cross_val_score(model, X, y, cv = kfold)\n",
    "accuracy = np.mean(abs(results_6))\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.840156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest Regressor k_fold</td>\n",
       "      <td>0.862227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.830253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boosting k_fold</td>\n",
       "      <td>0.855475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ada Boosting</td>\n",
       "      <td>0.707731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ada Boosting k_fold</td>\n",
       "      <td>0.723867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNN Regressor</td>\n",
       "      <td>0.732800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNN Regressor kfold</td>\n",
       "      <td>0.564854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bagging Regressor</td>\n",
       "      <td>0.836943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bagging Regressor kfold</td>\n",
       "      <td>0.852969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Algorithm  accuracy\n",
       "1                    Random Forest  0.840156\n",
       "2   Random Forest Regressor k_fold  0.862227\n",
       "3                Gradient Boosting  0.830253\n",
       "4         Gradient Boosting k_fold  0.855475\n",
       "5                     Ada Boosting  0.707731\n",
       "6              Ada Boosting k_fold  0.723867\n",
       "7                    KNN Regressor  0.732800\n",
       "8              KNN Regressor kfold  0.564854\n",
       "9                Bagging Regressor  0.836943\n",
       "10         Bagging Regressor kfold  0.852969"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the accuracy results for each model in a dataframe\n",
    "BaggingKfold_df = pd.DataFrame({'Algorithm':['Bagging Regressor kfold'], 'accuracy': [accuracy]}, index = {'10'})\n",
    "results = pd.concat([results, BaggingKfold_df])\n",
    "results = results[['Algorithm', 'accuracy']]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# support vector model\n",
    "model = SVR(kernel = 'linear')\n",
    "# fitting model\n",
    "model.fit(X_train, y_train)\n",
    "# predicted values\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6672091931234319"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model performance on training data\n",
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5691816797222073"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5691816797222073"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_SVR = metrics.r2_score(y_test, y_pred)\n",
    "acc_SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112.92058321167713"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE = metrics.mean_squared_error(y_test, y_pred)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.840156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest Regressor k_fold</td>\n",
       "      <td>0.862227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.830253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boosting k_fold</td>\n",
       "      <td>0.855475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ada Boosting</td>\n",
       "      <td>0.707731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ada Boosting k_fold</td>\n",
       "      <td>0.723867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNN Regressor</td>\n",
       "      <td>0.732800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNN Regressor kfold</td>\n",
       "      <td>0.564854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bagging Regressor</td>\n",
       "      <td>0.836943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bagging Regressor kfold</td>\n",
       "      <td>0.852969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bagging Regressor</td>\n",
       "      <td>0.569182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Algorithm  accuracy\n",
       "1                    Random Forest  0.840156\n",
       "2   Random Forest Regressor k_fold  0.862227\n",
       "3                Gradient Boosting  0.830253\n",
       "4         Gradient Boosting k_fold  0.855475\n",
       "5                     Ada Boosting  0.707731\n",
       "6              Ada Boosting k_fold  0.723867\n",
       "7                    KNN Regressor  0.732800\n",
       "8              KNN Regressor kfold  0.564854\n",
       "9                Bagging Regressor  0.836943\n",
       "10         Bagging Regressor kfold  0.852969\n",
       "11               Bagging Regressor  0.569182"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the accuracy results for each model in a dataframe\n",
    "SVR_df = pd.DataFrame({'Algorithm':['Bagging Regressor'], 'accuracy': [acc_SVR]}, index = {'11'})\n",
    "results = pd.concat([results, SVR_df])\n",
    "results = results[['Algorithm', 'accuracy']]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kfold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6249417071176954"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 20\n",
    "# creating k experiments in the dataset and taking its mean accuracy\n",
    "kfold = KFold(n_splits = k, random_state = 70, shuffle = True)\n",
    "results_7 = cross_val_score(model, X, y, cv = kfold)\n",
    "accuracy = np.mean(abs(results_7))\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.840156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest Regressor k_fold</td>\n",
       "      <td>0.862227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.830253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boosting k_fold</td>\n",
       "      <td>0.855475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ada Boosting</td>\n",
       "      <td>0.707731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ada Boosting k_fold</td>\n",
       "      <td>0.723867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNN Regressor</td>\n",
       "      <td>0.732800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNN Regressor kfold</td>\n",
       "      <td>0.564854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bagging Regressor</td>\n",
       "      <td>0.836943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bagging Regressor kfold</td>\n",
       "      <td>0.852969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bagging Regressor</td>\n",
       "      <td>0.569182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bagging Regressor kfold</td>\n",
       "      <td>0.836943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Algorithm  accuracy\n",
       "1                    Random Forest  0.840156\n",
       "2   Random Forest Regressor k_fold  0.862227\n",
       "3                Gradient Boosting  0.830253\n",
       "4         Gradient Boosting k_fold  0.855475\n",
       "5                     Ada Boosting  0.707731\n",
       "6              Ada Boosting k_fold  0.723867\n",
       "7                    KNN Regressor  0.732800\n",
       "8              KNN Regressor kfold  0.564854\n",
       "9                Bagging Regressor  0.836943\n",
       "10         Bagging Regressor kfold  0.852969\n",
       "11               Bagging Regressor  0.569182\n",
       "12         Bagging Regressor kfold  0.836943"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the accuracy results for each model in a dataframe\n",
    "BRKfold_df = pd.DataFrame({'Algorithm':['Bagging Regressor kfold'], 'accuracy': [acc_BR]}, index = {'12'})\n",
    "results = pd.concat([results, BRKfold_df])\n",
    "results = results[['Algorithm', 'accuracy']]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost regressor model\n",
    "xgr = XGBRegressor()\n",
    "# fitting model\n",
    "xgr.fit(X_train, y_train)\n",
    "# predicted values\n",
    "y_pred = xgr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9775344319902008"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model performance on training data\n",
    "xgr.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8315259195769521"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8315259195769521"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_XGB = metrics.r2_score(y_test, y_pred)\n",
    "acc_XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44.15826932604612"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE = metrics.mean_squared_error(y_test, y_pred)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.840156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest Regressor k_fold</td>\n",
       "      <td>0.862227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.830253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boosting k_fold</td>\n",
       "      <td>0.855475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ada Boosting</td>\n",
       "      <td>0.707731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ada Boosting k_fold</td>\n",
       "      <td>0.723867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNN Regressor</td>\n",
       "      <td>0.732800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNN Regressor kfold</td>\n",
       "      <td>0.564854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bagging Regressor</td>\n",
       "      <td>0.836943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bagging Regressor kfold</td>\n",
       "      <td>0.852969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bagging Regressor</td>\n",
       "      <td>0.569182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bagging Regressor kfold</td>\n",
       "      <td>0.836943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGBoost Regressor</td>\n",
       "      <td>0.831526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Algorithm  accuracy\n",
       "1                    Random Forest  0.840156\n",
       "2   Random Forest Regressor k_fold  0.862227\n",
       "3                Gradient Boosting  0.830253\n",
       "4         Gradient Boosting k_fold  0.855475\n",
       "5                     Ada Boosting  0.707731\n",
       "6              Ada Boosting k_fold  0.723867\n",
       "7                    KNN Regressor  0.732800\n",
       "8              KNN Regressor kfold  0.564854\n",
       "9                Bagging Regressor  0.836943\n",
       "10         Bagging Regressor kfold  0.852969\n",
       "11               Bagging Regressor  0.569182\n",
       "12         Bagging Regressor kfold  0.836943\n",
       "13               XGBoost Regressor  0.831526"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the accuracy results for each model in a dataframe\n",
    "XGB_df = pd.DataFrame({'Algorithm':['XGBoost Regressor'], 'accuracy': [acc_XGB]}, index = {'13'})\n",
    "results = pd.concat([results, XGB_df])\n",
    "results = results[['Algorithm', 'accuracy']]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kfold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8691748222147225"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 20\n",
    "# creating k experiments in the dataset and taking its mean accuracy\n",
    "kfold = KFold(n_splits = k, random_state = 70, shuffle = True)\n",
    "results_8 = cross_val_score(xgr, X, y, cv = kfold)\n",
    "accuracy = np.mean(abs(results_8))\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.840156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest Regressor k_fold</td>\n",
       "      <td>0.862227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.830253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boosting k_fold</td>\n",
       "      <td>0.855475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ada Boosting</td>\n",
       "      <td>0.707731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ada Boosting k_fold</td>\n",
       "      <td>0.723867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNN Regressor</td>\n",
       "      <td>0.732800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNN Regressor kfold</td>\n",
       "      <td>0.564854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bagging Regressor</td>\n",
       "      <td>0.836943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bagging Regressor kfold</td>\n",
       "      <td>0.852969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bagging Regressor</td>\n",
       "      <td>0.569182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bagging Regressor kfold</td>\n",
       "      <td>0.836943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGBoost Regressor</td>\n",
       "      <td>0.831526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XGBoost Regressor kfold</td>\n",
       "      <td>0.869175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Algorithm  accuracy\n",
       "1                    Random Forest  0.840156\n",
       "2   Random Forest Regressor k_fold  0.862227\n",
       "3                Gradient Boosting  0.830253\n",
       "4         Gradient Boosting k_fold  0.855475\n",
       "5                     Ada Boosting  0.707731\n",
       "6              Ada Boosting k_fold  0.723867\n",
       "7                    KNN Regressor  0.732800\n",
       "8              KNN Regressor kfold  0.564854\n",
       "9                Bagging Regressor  0.836943\n",
       "10         Bagging Regressor kfold  0.852969\n",
       "11               Bagging Regressor  0.569182\n",
       "12         Bagging Regressor kfold  0.836943\n",
       "13               XGBoost Regressor  0.831526\n",
       "14         XGBoost Regressor kfold  0.869175"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the accuracy results for each model in a dataframe\n",
    "XGBKFold_df = pd.DataFrame({'Algorithm':['XGBoost Regressor kfold'], 'accuracy': [accuracy]}, index = {'14'})\n",
    "results = pd.concat([results, XGBKFold_df])\n",
    "results = results[['Algorithm', 'accuracy']]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost regressor model\n",
    "dec_model = DecisionTreeRegressor()\n",
    "# fitting model\n",
    "dec_model.fit(X_train, y_train)\n",
    "# predicted values\n",
    "y_pred = dec_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances: \n",
      "               Importance\n",
      "cement          0.262189\n",
      "slag            0.062382\n",
      "ash             0.030395\n",
      "water           0.207650\n",
      "superplastic    0.034205\n",
      "coarseagg       0.025863\n",
      "fineagg         0.061014\n",
      "age             0.316301\n"
     ]
    }
   ],
   "source": [
    "# Checking the feature importance\n",
    "print('Feature importances: \\n', pd.DataFrame(dec_model.feature_importances_, columns = ['Importance'], index = X_train.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important features are age, cement and water."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dec_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9781185661281978"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model performance on training data\n",
    "dec_model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7651920348122582"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7651920348122582"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_DT = metrics.r2_score(y_test, y_pred)\n",
    "acc_DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.54485806139878"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE = metrics.mean_squared_error(y_test, y_pred)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.840156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest Regressor k_fold</td>\n",
       "      <td>0.862227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.830253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boosting k_fold</td>\n",
       "      <td>0.855475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ada Boosting</td>\n",
       "      <td>0.707731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ada Boosting k_fold</td>\n",
       "      <td>0.723867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNN Regressor</td>\n",
       "      <td>0.732800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNN Regressor kfold</td>\n",
       "      <td>0.564854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bagging Regressor</td>\n",
       "      <td>0.836943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bagging Regressor kfold</td>\n",
       "      <td>0.852969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bagging Regressor</td>\n",
       "      <td>0.569182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bagging Regressor kfold</td>\n",
       "      <td>0.836943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGBoost Regressor</td>\n",
       "      <td>0.831526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XGBoost Regressor kfold</td>\n",
       "      <td>0.869175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Decision Tree Regressor</td>\n",
       "      <td>0.765192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Algorithm  accuracy\n",
       "1                    Random Forest  0.840156\n",
       "2   Random Forest Regressor k_fold  0.862227\n",
       "3                Gradient Boosting  0.830253\n",
       "4         Gradient Boosting k_fold  0.855475\n",
       "5                     Ada Boosting  0.707731\n",
       "6              Ada Boosting k_fold  0.723867\n",
       "7                    KNN Regressor  0.732800\n",
       "8              KNN Regressor kfold  0.564854\n",
       "9                Bagging Regressor  0.836943\n",
       "10         Bagging Regressor kfold  0.852969\n",
       "11               Bagging Regressor  0.569182\n",
       "12         Bagging Regressor kfold  0.836943\n",
       "13               XGBoost Regressor  0.831526\n",
       "14         XGBoost Regressor kfold  0.869175\n",
       "15         Decision Tree Regressor  0.765192"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the accuracy results for each model in a dataframe\n",
    "DT_df = pd.DataFrame({'Algorithm':['Decision Tree Regressor'], 'accuracy': [acc_DT]}, index = {'15'})\n",
    "results = pd.concat([results, DT_df])\n",
    "results = results[['Algorithm', 'accuracy']]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kfold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7868284320608908"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 20\n",
    "# creating k experiments in the dataset and taking its mean accuracy\n",
    "kfold = KFold(n_splits = k, random_state = 70, shuffle = True)\n",
    "results_9 = cross_val_score(dec_model, X, y, cv = kfold)\n",
    "accuracy = np.mean(abs(results_9))\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.840156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest Regressor k_fold</td>\n",
       "      <td>0.862227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.830253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boosting k_fold</td>\n",
       "      <td>0.855475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ada Boosting</td>\n",
       "      <td>0.707731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ada Boosting k_fold</td>\n",
       "      <td>0.723867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNN Regressor</td>\n",
       "      <td>0.732800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNN Regressor kfold</td>\n",
       "      <td>0.564854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bagging Regressor</td>\n",
       "      <td>0.836943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bagging Regressor kfold</td>\n",
       "      <td>0.852969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bagging Regressor</td>\n",
       "      <td>0.569182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bagging Regressor kfold</td>\n",
       "      <td>0.836943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGBoost Regressor</td>\n",
       "      <td>0.831526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XGBoost Regressor kfold</td>\n",
       "      <td>0.869175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Decision Tree Regressor</td>\n",
       "      <td>0.765192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Decision Tree Regressor kfold</td>\n",
       "      <td>0.786828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Algorithm  accuracy\n",
       "1                    Random Forest  0.840156\n",
       "2   Random Forest Regressor k_fold  0.862227\n",
       "3                Gradient Boosting  0.830253\n",
       "4         Gradient Boosting k_fold  0.855475\n",
       "5                     Ada Boosting  0.707731\n",
       "6              Ada Boosting k_fold  0.723867\n",
       "7                    KNN Regressor  0.732800\n",
       "8              KNN Regressor kfold  0.564854\n",
       "9                Bagging Regressor  0.836943\n",
       "10         Bagging Regressor kfold  0.852969\n",
       "11               Bagging Regressor  0.569182\n",
       "12         Bagging Regressor kfold  0.836943\n",
       "13               XGBoost Regressor  0.831526\n",
       "14         XGBoost Regressor kfold  0.869175\n",
       "15         Decision Tree Regressor  0.765192\n",
       "16   Decision Tree Regressor kfold  0.786828"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the accuracy results for each model in a dataframe\n",
    "DTKFold_df = pd.DataFrame({'Algorithm':['Decision Tree Regressor kfold'], 'accuracy': [accuracy]}, index = {'16'})\n",
    "results = pd.concat([results, DTKFold_df])\n",
    "results = results[['Algorithm', 'accuracy']]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with the most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy() # create a copy in order to drop the least important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the most important features as the X dataset\n",
    "X = df2.drop(columns = ['strength', 'ash', 'coarseagg', 'fineagg'], axis = 1)\n",
    "y = df2[['strength']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting into train and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scalling the train dependent variables\n",
    "X_train = X_train.apply(zscore)\n",
    "# scalling the test dependent variables\n",
    "X_test = X_test.apply(zscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# decision tree regressor model with most important features\n",
    "decNew_model = DecisionTreeRegressor()\n",
    "# fitting the model\n",
    "decNew_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances: \n",
      "               Importance\n",
      "cement          0.315359\n",
      "slag            0.089117\n",
      "water           0.221527\n",
      "superplastic    0.055917\n",
      "age             0.318081\n"
     ]
    }
   ],
   "source": [
    "# Checking the feature importance again\n",
    "print('Feature importances: \\n', pd.DataFrame(decNew_model.feature_importances_, columns = ['Importance'], index = X_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = decNew_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9762602947409703"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decNew_model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6134571646737967"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decNew_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6134571646737967"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_DT = metrics.r2_score(y_test, y_pred)\n",
    "acc_DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101.31565986605537"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE = metrics.mean_squared_error(y_test, y_pred)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.840156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest Regressor k_fold</td>\n",
       "      <td>0.862227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.830253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boosting k_fold</td>\n",
       "      <td>0.855475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ada Boosting</td>\n",
       "      <td>0.707731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ada Boosting k_fold</td>\n",
       "      <td>0.723867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNN Regressor</td>\n",
       "      <td>0.732800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNN Regressor kfold</td>\n",
       "      <td>0.564854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bagging Regressor</td>\n",
       "      <td>0.836943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bagging Regressor kfold</td>\n",
       "      <td>0.852969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bagging Regressor</td>\n",
       "      <td>0.569182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bagging Regressor kfold</td>\n",
       "      <td>0.836943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGBoost Regressor</td>\n",
       "      <td>0.831526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XGBoost Regressor kfold</td>\n",
       "      <td>0.869175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Decision Tree Regressor</td>\n",
       "      <td>0.765192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Decision Tree Regressor kfold</td>\n",
       "      <td>0.786828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Decision Tree 2</td>\n",
       "      <td>0.613457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Algorithm  accuracy\n",
       "1                    Random Forest  0.840156\n",
       "2   Random Forest Regressor k_fold  0.862227\n",
       "3                Gradient Boosting  0.830253\n",
       "4         Gradient Boosting k_fold  0.855475\n",
       "5                     Ada Boosting  0.707731\n",
       "6              Ada Boosting k_fold  0.723867\n",
       "7                    KNN Regressor  0.732800\n",
       "8              KNN Regressor kfold  0.564854\n",
       "9                Bagging Regressor  0.836943\n",
       "10         Bagging Regressor kfold  0.852969\n",
       "11               Bagging Regressor  0.569182\n",
       "12         Bagging Regressor kfold  0.836943\n",
       "13               XGBoost Regressor  0.831526\n",
       "14         XGBoost Regressor kfold  0.869175\n",
       "15         Decision Tree Regressor  0.765192\n",
       "16   Decision Tree Regressor kfold  0.786828\n",
       "17                 Decision Tree 2  0.613457"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the accuracy results for each model in a dataframe\n",
    "Dec_df1 = pd.DataFrame({'Algorithm':['Decision Tree 2'], 'accuracy': [acc_DT]}, index = {'17'})\n",
    "results = pd.concat([results, Dec_df1])\n",
    "results = results[['Algorithm', 'accuracy']]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8017093355830116"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 20\n",
    "# creating k experiments in the dataset and taking its mean accuracy\n",
    "kfold = KFold(n_splits = k, random_state = 70, shuffle = True)\n",
    "results_10 = cross_val_score(decNew_model, X, y, cv = kfold)\n",
    "accuracy = np.mean(abs(results_10))\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.840156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest Regressor k_fold</td>\n",
       "      <td>0.862227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.830253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boosting k_fold</td>\n",
       "      <td>0.855475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ada Boosting</td>\n",
       "      <td>0.707731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ada Boosting k_fold</td>\n",
       "      <td>0.723867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNN Regressor</td>\n",
       "      <td>0.732800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNN Regressor kfold</td>\n",
       "      <td>0.564854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bagging Regressor</td>\n",
       "      <td>0.836943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bagging Regressor kfold</td>\n",
       "      <td>0.852969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bagging Regressor</td>\n",
       "      <td>0.569182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bagging Regressor kfold</td>\n",
       "      <td>0.836943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGBoost Regressor</td>\n",
       "      <td>0.831526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XGBoost Regressor kfold</td>\n",
       "      <td>0.869175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Decision Tree Regressor</td>\n",
       "      <td>0.765192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Decision Tree Regressor kfold</td>\n",
       "      <td>0.786828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Decision Tree 2</td>\n",
       "      <td>0.613457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Decision Tree 2 kfold</td>\n",
       "      <td>0.801709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Algorithm  accuracy\n",
       "1                    Random Forest  0.840156\n",
       "2   Random Forest Regressor k_fold  0.862227\n",
       "3                Gradient Boosting  0.830253\n",
       "4         Gradient Boosting k_fold  0.855475\n",
       "5                     Ada Boosting  0.707731\n",
       "6              Ada Boosting k_fold  0.723867\n",
       "7                    KNN Regressor  0.732800\n",
       "8              KNN Regressor kfold  0.564854\n",
       "9                Bagging Regressor  0.836943\n",
       "10         Bagging Regressor kfold  0.852969\n",
       "11               Bagging Regressor  0.569182\n",
       "12         Bagging Regressor kfold  0.836943\n",
       "13               XGBoost Regressor  0.831526\n",
       "14         XGBoost Regressor kfold  0.869175\n",
       "15         Decision Tree Regressor  0.765192\n",
       "16   Decision Tree Regressor kfold  0.786828\n",
       "17                 Decision Tree 2  0.613457\n",
       "18           Decision Tree 2 kfold  0.801709"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the accuracy results for each model in a dataframe\n",
    "DTKFold_df = pd.DataFrame({'Algorithm':['Decision Tree 2 kfold'], 'accuracy': [accuracy]}, index = {'18'})\n",
    "results = pd.concat([results, DTKFold_df])\n",
    "results = results[['Algorithm', 'accuracy']]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XGBoost Regressor kfold</td>\n",
       "      <td>0.869175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest Regressor k_fold</td>\n",
       "      <td>0.862227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boosting k_fold</td>\n",
       "      <td>0.855475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bagging Regressor kfold</td>\n",
       "      <td>0.852969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.840156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bagging Regressor</td>\n",
       "      <td>0.836943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bagging Regressor kfold</td>\n",
       "      <td>0.836943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGBoost Regressor</td>\n",
       "      <td>0.831526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.830253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Decision Tree 2 kfold</td>\n",
       "      <td>0.801709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Decision Tree Regressor kfold</td>\n",
       "      <td>0.786828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Decision Tree Regressor</td>\n",
       "      <td>0.765192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNN Regressor</td>\n",
       "      <td>0.732800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ada Boosting k_fold</td>\n",
       "      <td>0.723867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ada Boosting</td>\n",
       "      <td>0.707731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Decision Tree 2</td>\n",
       "      <td>0.613457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bagging Regressor</td>\n",
       "      <td>0.569182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNN Regressor kfold</td>\n",
       "      <td>0.564854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Algorithm  accuracy\n",
       "14         XGBoost Regressor kfold  0.869175\n",
       "2   Random Forest Regressor k_fold  0.862227\n",
       "4         Gradient Boosting k_fold  0.855475\n",
       "10         Bagging Regressor kfold  0.852969\n",
       "1                    Random Forest  0.840156\n",
       "9                Bagging Regressor  0.836943\n",
       "12         Bagging Regressor kfold  0.836943\n",
       "13               XGBoost Regressor  0.831526\n",
       "3                Gradient Boosting  0.830253\n",
       "18           Decision Tree 2 kfold  0.801709\n",
       "16   Decision Tree Regressor kfold  0.786828\n",
       "15         Decision Tree Regressor  0.765192\n",
       "7                    KNN Regressor  0.732800\n",
       "6              Ada Boosting k_fold  0.723867\n",
       "5                     Ada Boosting  0.707731\n",
       "17                 Decision Tree 2  0.613457\n",
       "11               Bagging Regressor  0.569182\n",
       "8              KNN Regressor kfold  0.564854"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values(by = 'accuracy', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the best results were given by XGBoost and Random Forest regressors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c3503f95e0e8f4afdf6702396a7a2a29cae9f67572acfe092405dcaa2579b817"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
